#!/usr/bin/env python
# -*- coding: utf-8 -*-

import numpy as np
import matplotlib.pyplot as plt
import matplotlib as mpl
from IPython.display import SVG
from keras.utils.vis_utils import model_to_dot, plot_model
from keras.datasets import mnist

mpl.rc('font', size=15)
mpl.rc('figure', figsize=(8, 5))

from keras.models import Sequential

import model as mod

if __name__ == '__main__':

    # train on MNIST data
    (x_train, y_train), (x_test, y_test) = mnist.load_data()

    x_train = x_train.astype(float) / 255.
    x_test = x_test.astype(float) / 255.
    x_train = x_train.reshape(*x_train.shape, 1)
    x_test = x_test.reshape(*x_test.shape, 1)

    # create autoencoder
    encoder = mod.encoder_model(reg=0)
    decoder = mod.decoder_model(reg=0)
    plot_model(encoder, to_file='plots/encoder.png', show_shapes=True,
               show_layer_names=True)
    plot_model(decoder, to_file='plots/decoder.png', show_shapes=True,
               show_layer_names=True)

    autoencoder = Sequential(name='convolutional_autoencoder')
    autoencoder.add(encoder)
    autoencoder.add(decoder)
    autoencoder.compile(loss='binary_crossentropy', optimizer='rmsprop')
    plot_model(autoencoder, to_file='plots/autoencoder.png', show_shapes=True,
               show_layer_names=True)

    # training
    stats = autoencoder.fit(x_train, x_train,
                           epochs=20,
                           batch_size=128,
                           shuffle=True,
                           validation_data=(x_test, x_test))

    # save model
    encoder.save('models/encoder.h5')
    decoder.save('models/decoder.h5')
    autoencoder.save('models/conv_encoder.h5')

    # plot
    fig, ax = plt.subplots(1)
    epochs = np.arange(1, 21)
    ax.plot(epochs, stats.history['loss'], label='training loss')
    ax.plot(epochs, stats.history['val_loss'], label='validation loss')
    ax.set(xlabel='epochs', ylabel='loss')
    ax.grid(ls='--')
    ax.legend()
    plt.save_fig('plots/loss_curve.png', dpi=100, bbox_inches='tight')
